{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7293eafd-d60b-4aab-b34e-ad97f603e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4594055e-7b88-460c-af6c-ad827811f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"forestCover.csv\", na_values=['?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f7d756-66cd-4687-bc96-0cc83b20fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Water_Level', 'Observation_ID',\"Inclination\", \"Facet\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "562d95e4-ef6e-4ec9-900b-40d781803967",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Soil_Type1'] = df['Soil_Type1'].map({'positive': 0, 'negative': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a29ed9-7274-4a80-9ddd-1e918558d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"df_tree_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a827857-1d55-429e-9721-e1d4d5f6d2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((464809, 54), (116203, 54), (464809,), (116203,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_col = \"Cover_Type\"\n",
    "\n",
    "y = df[target_col]\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    stratify=y,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062922b6-c6ec-4bc2-963f-76c67fd290e3",
   "metadata": {},
   "source": [
    "# Impute missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45ba9db5-0bf8-4980-9236-1ff52d20efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Compute median from training set only\n",
    "slope_median = X_train[\"Slope\"].median()\n",
    "\n",
    " Impute in training and test set using the same median\n",
    "X_train[\"Slope\"] = X_train[\"Slope\"].fillna(slope_median)\n",
    "X_test[\"Slope\"]  = X_test[\"Slope\"].fillna(slope_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2334109a-27f0-4fcb-a7b0-e98007fe8786",
   "metadata": {},
   "source": [
    "# SKEWNESS : CLASS WEIGHT = BALANCED + strat folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dbbf2e9-3650-4c5c-95d7-6ba0ce174706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Starting Tree Hyperband (balanced_accuracy)…\n",
      "n_iterations: 9\n",
      "n_required_iterations: 9\n",
      "n_possible_iterations: 9\n",
      "min_resources_: 70\n",
      "max_resources_: 464809\n",
      "aggressive_elimination: True\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 6640\n",
      "n_resources: 70\n",
      "Fitting 5 folds for each of 6640 candidates, totalling 33200 fits\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\queues.py\", line 159, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 215, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 208, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\externals\\cloudpickle\\cloudpickle.py\", line 1245, in dump\n    return super().dump(obj)\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\_memmapping_reducer.py\", line 451, in __call__\n    for dumped_filename in dump(a, filename):\n                           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py\", line 553, in dump\n    NumpyPickler(f, protocol=protocol).dump(value)\n  File \"C:\\Users\\User\\anaconda3\\Lib\\pickle.py\", line 484, in dump\n    self.save(obj)\n  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py\", line 352, in save\n    wrapper.write_array(obj, self)\n  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py\", line 134, in write_array\n    pickler.file_handle.write(chunk.tobytes('C'))\nOSError: [Errno 28] No space left on device\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>> Starting Tree Hyperband (balanced_accuracy)…\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 60\u001b[0m search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     61\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Hyperband DONE ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search_successive_halving.py:253\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input_parameters(\n\u001b[0;32m    248\u001b[0m     X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, split_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit\n\u001b[0;32m    249\u001b[0m )\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_samples_orig \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[1;32m--> 253\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    255\u001b[0m \u001b[38;5;66;03m# Set best_score_: BaseSearchCV does not set it, as refit is a callable\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_index_]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1046\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1047\u001b[0m     )\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search_successive_halving.py:357\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    350\u001b[0m     cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checked_cv_orig\n\u001b[0;32m    352\u001b[0m more_results \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miter\u001b[39m\u001b[38;5;124m\"\u001b[39m: [itr] \u001b[38;5;241m*\u001b[39m n_candidates,\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_resources\u001b[39m\u001b[38;5;124m\"\u001b[39m: [n_resources] \u001b[38;5;241m*\u001b[39m n_candidates,\n\u001b[0;32m    355\u001b[0m }\n\u001b[1;32m--> 357\u001b[0m results \u001b[38;5;241m=\u001b[39m evaluate_candidates(\n\u001b[0;32m    358\u001b[0m     candidate_params, cv, more_results\u001b[38;5;241m=\u001b[39mmore_results\n\u001b[0;32m    359\u001b[0m )\n\u001b[0;32m    361\u001b[0m n_candidates_to_keep \u001b[38;5;241m=\u001b[39m ceil(n_candidates \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfactor)\n\u001b[0;32m    362\u001b[0m candidate_params \u001b[38;5;241m=\u001b[39m _top_k(results, n_candidates_to_keep, itr)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    993\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    994\u001b[0m         )\n\u001b[0;32m    995\u001b[0m     )\n\u001b[1;32m--> 997\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    998\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    999\u001b[0m         clone(base_estimator),\n\u001b[0;32m   1000\u001b[0m         X,\n\u001b[0;32m   1001\u001b[0m         y,\n\u001b[0;32m   1002\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m   1003\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m   1004\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m   1005\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m   1006\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m   1007\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m   1008\u001b[0m     )\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m   1010\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m   1011\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m   1012\u001b[0m     )\n\u001b[0;32m   1013\u001b[0m )\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1017\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1019\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1020\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     75\u001b[0m     (\n\u001b[0;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config_and_warning_filters)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_error_fast()\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     error_job\u001b[38;5;241m.\u001b[39mget_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_or_raise()\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mPicklingError\u001b[0m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "import time, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    HalvingRandomSearchCV,\n",
    "    cross_validate,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score, matthews_corrcoef\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0,\n",
    "                             class_weight=\"balanced\")\n",
    "\n",
    "\n",
    "param_distributions = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],  \n",
    "    \"splitter\": [\"best\", \"random\"],\n",
    "    \"max_depth\": randint(4, 60),                    \n",
    "    \"min_samples_split\": randint(2, 100),\n",
    "    \"min_samples_leaf\": randint(1, 50),\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"],\n",
    "    \"ccp_alpha\": uniform(0.0, 0.02),               \n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "search = HalvingRandomSearchCV(\n",
    "    estimator=tree,\n",
    "    param_distributions=param_distributions,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    refit=True,                     # refit best on FULL training split\n",
    "    cv=cv,\n",
    "    factor=3,\n",
    "    resource=\"n_samples\",\n",
    "    min_resources=\"smallest\",\n",
    "    aggressive_elimination=True,\n",
    "    n_candidates=\"exhaust\",\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    error_score=np.nan,\n",
    "    return_train_score=False,\n",
    ")\n",
    "\n",
    "print(\">>> Starting Tree Hyperband (balanced_accuracy)…\")\n",
    "t0 = time.time()\n",
    "search.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print(\"\\n=== Hyperband DONE ===\")\n",
    "print(f\"Elapsed: {t1 - t0:.1f}s\")\n",
    "print(\"Best params:\", search.best_params_)\n",
    "print(f\"Best CV balanced_accuracy: {search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a7ef854-a73d-45d7-baf3-83a9ca4a4120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score, matthews_corrcoef\n",
    "\n",
    "multi_scoring = {\n",
    "    \"balanced_accuracy\": \"balanced_accuracy\",\n",
    "    \"macro_f1\": make_scorer(f1_score, average=\"macro\", zero_division=0),\n",
    "    \"weighted_f1\": make_scorer(f1_score, average=\"weighted\", zero_division=0),\n",
    "    \"mcc\": make_scorer(matthews_corrcoef),\n",
    "}\n",
    "\n",
    "# Helper for nice output\n",
    "def mean_std_str(values):\n",
    "    return f\"{np.mean(values):.3f} ± {np.std(values, ddof=1):.3f}\"\n",
    "\n",
    "# Consistent CV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv_post = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df96dbcb-32c2-4360-9032-0ab89f6ed106",
   "metadata": {},
   "source": [
    "# Halving CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563e3d14-29eb-4e69-a357-29ded0e265c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "-\n",
    "def acc_key(row):\n",
    "    p = row[\"params\"]\n",
    "    return (\n",
    "        p.get(\"criterion\"),\n",
    "        p.get(\"splitter\"),\n",
    "        p.get(\"max_depth\"),\n",
    "        p.get(\"min_samples_split\"),\n",
    "        p.get(\"min_samples_leaf\"),\n",
    "        p.get(\"max_features\"),\n",
    "        p.get(\"ccp_alpha\"),\n",
    "        p.get(\"class_weight\", \"balanced\"),\n",
    "    )\n",
    "\n",
    "cv_df[\"acc_key\"] = cv_df.apply(acc_key, axis=1)\n",
    "cv_df_unique = (cv_df.sort_values(\"rank_test_score\")\n",
    "                  .drop_duplicates(subset=\"acc_key\", keep=\"first\")\n",
    "                  .reset_index(drop=True))\n",
    "top5 = cv_df_unique.head(5).reset_index(drop=True)\n",
    "\n",
    "splits = list(cv.split(X_train, y_train))   # cv is the same StratifiedKFold used in search\n",
    "cv_post = splits\n",
    "\n",
    "rows = []\n",
    "for _, row in top5.iterrows():\n",
    "    params = dict(row[\"params\"])\n",
    "    params.pop(\"random_state\", None)  # ensure no conflict\n",
    "    # IMPORTANT: preserve class_weight used in the search\n",
    "    cand = DecisionTreeClassifier(random_state=0, class_weight=\"balanced\", **params)\n",
    "\n",
    "    res = cross_validate(\n",
    "        cand, X_train, y_train,\n",
    "        scoring=multi_scoring,\n",
    "        cv=cv_post,               # same folds as search\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "    rows.append({\n",
    "        \"rank\": int(row[\"rank_test_score\"]),\n",
    "        \"params\": params,\n",
    "        \"balanced_accuracy\": mean_std_str(res[\"test_balanced_accuracy\"]),\n",
    "        \"macro_f1\":          mean_std_str(res[\"test_macro_f1\"]),\n",
    "        \"weighted_f1\":       mean_std_str(res[\"test_weighted_f1\"]),\n",
    "        \"mcc\":               mean_std_str(res[\"test_mcc\"]),\n",
    "    })\n",
    "\n",
    "top5_multi = pd.DataFrame(rows).sort_values(\"rank\").reset_index(drop=True)\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    print(\"\\n=== Decision Tree | Top-5 (by balanced_accuracy rank) | Multi-metric CV (mean ± std) ===\")\n",
    "    print(top5_multi.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bd9f6f5-9980-424d-8fbd-580c5eeeca75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>params</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_f1</th>\n",
       "      <th>mcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'ccp_alpha': 6.8172494472173995e-06, 'criteri...</td>\n",
       "      <td>0.818 ± 0.003</td>\n",
       "      <td>0.827 ± 0.004</td>\n",
       "      <td>0.885 ± 0.001</td>\n",
       "      <td>0.815 ± 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>{'ccp_alpha': 5.5419132513638835e-05, 'criteri...</td>\n",
       "      <td>0.810 ± 0.006</td>\n",
       "      <td>0.819 ± 0.005</td>\n",
       "      <td>0.878 ± 0.001</td>\n",
       "      <td>0.803 ± 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>{'ccp_alpha': 0.00014236695335442028, 'criteri...</td>\n",
       "      <td>0.674 ± 0.008</td>\n",
       "      <td>0.705 ± 0.005</td>\n",
       "      <td>0.797 ± 0.003</td>\n",
       "      <td>0.675 ± 0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>{'ccp_alpha': 0.00032337351230194767, 'criteri...</td>\n",
       "      <td>0.587 ± 0.035</td>\n",
       "      <td>0.617 ± 0.029</td>\n",
       "      <td>0.757 ± 0.004</td>\n",
       "      <td>0.611 ± 0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>{'ccp_alpha': 0.000506289213397042, 'criterion...</td>\n",
       "      <td>0.545 ± 0.019</td>\n",
       "      <td>0.574 ± 0.016</td>\n",
       "      <td>0.734 ± 0.006</td>\n",
       "      <td>0.578 ± 0.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank                                             params balanced_accuracy  \\\n",
       "0     1  {'ccp_alpha': 6.8172494472173995e-06, 'criteri...     0.818 ± 0.003   \n",
       "1     2  {'ccp_alpha': 5.5419132513638835e-05, 'criteri...     0.810 ± 0.006   \n",
       "2     5  {'ccp_alpha': 0.00014236695335442028, 'criteri...     0.674 ± 0.008   \n",
       "3     6  {'ccp_alpha': 0.00032337351230194767, 'criteri...     0.587 ± 0.035   \n",
       "4    11  {'ccp_alpha': 0.000506289213397042, 'criterion...     0.545 ± 0.019   \n",
       "\n",
       "        macro_f1    weighted_f1            mcc  \n",
       "0  0.827 ± 0.004  0.885 ± 0.001  0.815 ± 0.002  \n",
       "1  0.819 ± 0.005  0.878 ± 0.001  0.803 ± 0.002  \n",
       "2  0.705 ± 0.005  0.797 ± 0.003  0.675 ± 0.004  \n",
       "3  0.617 ± 0.029  0.757 ± 0.004  0.611 ± 0.005  \n",
       "4  0.574 ± 0.016  0.734 ± 0.006  0.578 ± 0.010  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371a7e80-dbc0-411e-a263-41cf556ed31a",
   "metadata": {},
   "source": [
    "# not good enough when compared to KNN also fast try more in detail search. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbf50dc-60bd-480b-9927-8800ab67484e",
   "metadata": {},
   "source": [
    "# BO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5e4d36a-d7f5-4b94-b682-c26f213ee9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Categorical, Real\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np, pandas as pd, joblib, json, time, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41feb655-2ce7-4cad-8663-c046c83117b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "[BO] Done in 299.1s\n",
      "Best params: OrderedDict([('ccp_alpha', 5.141449890033588e-06), ('criterion', 'log_loss'), ('max_depth', 80), ('max_features', None), ('min_samples_leaf', 1), ('min_samples_split', 21), ('splitter', 'best')])\n",
      "Best CV balanced_accuracy: 0.9002\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "search_spaces = {\n",
    "    \"criterion\": Categorical([\"gini\", \"log_loss\"]),\n",
    "    \"splitter\":  Categorical([\"best\", \"random\"]),\n",
    "    \"max_depth\": Integer(8, 80),\n",
    "    \"min_samples_split\": Integer(2, 200),\n",
    "    \"min_samples_leaf\":  Integer(1, 80),\n",
    "    \"max_features\": Categorical([None, \"sqrt\", \"log2\"]),\n",
    "    # log-scaled ccp_alpha: explore small pruning values carefully\n",
    "    \"ccp_alpha\": Real(1e-6, 2e-2, prior=\"log-uniform\"),\n",
    "}\n",
    "\n",
    "tree_base = DecisionTreeClassifier(\n",
    "    random_state=0,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "bayes = BayesSearchCV(\n",
    "    estimator=tree_base,\n",
    "    search_spaces=search_spaces,\n",
    "    n_iter=50,                      \n",
    "    scoring=\"balanced_accuracy\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,                   \n",
    "    refit=True,                    \n",
    "    random_state=0,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "t0 = time.time()\n",
    "bayes.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print(f\"\\n[BO] Done in {t1 - t0:.1f}s\")\n",
    "print(\"Best params:\", bayes.best_params_)\n",
    "print(f\"Best CV balanced_accuracy: {bayes.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92dfbdd-5f32-408d-aa09-847ae5815274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed40d9f0-f87e-45a1-badf-2cbb50f8239a",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d843ac-4d37-4726-92a1-58d2ef50134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fitted best model + params\n",
    "os.makedirs(\"tree_artifacts\", exist_ok=True)\n",
    "joblib.dump(bayes.best_estimator_, \"tree_artifacts/tree_best_model.pkl\", compress=3)\n",
    "with open(\"tree_artifacts/tree_best_params.json\", \"w\") as f:\n",
    "    json.dump(bayes.best_params_, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c42b4-8556-4ddd-9209-cfe10c6bc36b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41ef9e04-a99e-4243-8e96-d6b0dfb4a7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Decision Tree (Bayes) | Top-5 UNIQUE by balanced_acc rank | Multi-metric CV (mean ± std) ===\n",
      " rank                                                                                                                                                                                               params balanced_accuracy      macro_f1   weighted_f1           mcc\n",
      "    1 {'ccp_alpha': 5.141449890033588e-06, 'criterion': 'log_loss', 'max_depth': 80, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 21, 'splitter': 'best', 'class_weight': 'balanced'}     0.900 ± 0.003 0.854 ± 0.003 0.913 ± 0.001 0.860 ± 0.002\n",
      "    2 {'ccp_alpha': 4.803358932542255e-06, 'criterion': 'log_loss', 'max_depth': 80, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 26, 'splitter': 'best', 'class_weight': 'balanced'}     0.900 ± 0.002 0.844 ± 0.003 0.907 ± 0.001 0.852 ± 0.002\n",
      "    3 {'ccp_alpha': 5.052652197728508e-06, 'criterion': 'log_loss', 'max_depth': 80, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 27, 'splitter': 'best', 'class_weight': 'balanced'}     0.899 ± 0.002 0.843 ± 0.002 0.906 ± 0.001 0.850 ± 0.002\n",
      "    4 {'ccp_alpha': 4.718810292020584e-06, 'criterion': 'log_loss', 'max_depth': 80, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 25, 'splitter': 'best', 'class_weight': 'balanced'}     0.899 ± 0.002 0.846 ± 0.002 0.909 ± 0.001 0.854 ± 0.002\n",
      "    5     {'ccp_alpha': 4.959218335617341e-06, 'criterion': 'gini', 'max_depth': 80, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 20, 'splitter': 'best', 'class_weight': 'balanced'}     0.898 ± 0.004 0.843 ± 0.004 0.903 ± 0.001 0.845 ± 0.002\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score, matthews_corrcoef\n",
    "\n",
    "cv_df = pd.DataFrame(bayes.cv_results_).copy()\n",
    "\n",
    "def acc_key(row):\n",
    "    p = row[\"params\"]\n",
    "    return (\n",
    "        p.get(\"criterion\"),\n",
    "        p.get(\"splitter\"),\n",
    "        p.get(\"max_depth\"),\n",
    "        p.get(\"min_samples_split\"),\n",
    "        p.get(\"min_samples_leaf\"),\n",
    "        p.get(\"max_features\"),\n",
    "        p.get(\"ccp_alpha\"),\n",
    "    )\n",
    "\n",
    "cv_df[\"acc_key\"] = cv_df.apply(acc_key, axis=1)\n",
    "\n",
    "cv_df_unique = (cv_df.sort_values(\"rank_test_score\")\n",
    "                  .drop_duplicates(subset=\"acc_key\", keep=\"first\")\n",
    "                  .reset_index(drop=True))\n",
    "\n",
    "top5 = cv_df_unique.head(5).reset_index(drop=True)\n",
    "\n",
    "rows = []\n",
    "for _, row in top5.iterrows():\n",
    "    params = row[\"params\"].copy()\n",
    "\n",
    "    params[\"class_weight\"] = \"balanced\"\n",
    "\n",
    "    cand = DecisionTreeClassifier(random_state=0, **params)\n",
    "\n",
    "    res = cross_validate(\n",
    "        cand, X_train, y_train,\n",
    "        scoring=multi_scoring,\n",
    "        cv=cv_post,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "\n",
    "    rows.append({\n",
    "        \"rank\": int(row[\"rank_test_score\"]),\n",
    "        \"params\": params,\n",
    "        \"balanced_accuracy\": mean_std_str(res[\"test_balanced_accuracy\"]),\n",
    "        \"macro_f1\":          mean_std_str(res[\"test_macro_f1\"]),\n",
    "        \"weighted_f1\":       mean_std_str(res[\"test_weighted_f1\"]),\n",
    "        \"mcc\":               mean_std_str(res[\"test_mcc\"]),\n",
    "    })\n",
    "\n",
    "top5_multi = pd.DataFrame(rows).sort_values(\"rank\").reset_index(drop=True)\n",
    "\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    print(\"\\n=== Decision Tree (Bayes) | Top-5 UNIQUE by balanced_acc rank | Multi-metric CV (mean ± std) ===\")\n",
    "    print(top5_multi.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08c6c83e-e9fb-4306-9570-3f7bc8f6ecc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>params</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_f1</th>\n",
       "      <th>mcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'ccp_alpha': 5.141449890033588e-06, 'criterio...</td>\n",
       "      <td>0.900 ± 0.003</td>\n",
       "      <td>0.854 ± 0.003</td>\n",
       "      <td>0.913 ± 0.001</td>\n",
       "      <td>0.860 ± 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>{'ccp_alpha': 4.803358932542255e-06, 'criterio...</td>\n",
       "      <td>0.900 ± 0.002</td>\n",
       "      <td>0.844 ± 0.003</td>\n",
       "      <td>0.907 ± 0.001</td>\n",
       "      <td>0.852 ± 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>{'ccp_alpha': 5.052652197728508e-06, 'criterio...</td>\n",
       "      <td>0.899 ± 0.002</td>\n",
       "      <td>0.843 ± 0.002</td>\n",
       "      <td>0.906 ± 0.001</td>\n",
       "      <td>0.850 ± 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>{'ccp_alpha': 4.718810292020584e-06, 'criterio...</td>\n",
       "      <td>0.899 ± 0.002</td>\n",
       "      <td>0.846 ± 0.002</td>\n",
       "      <td>0.909 ± 0.001</td>\n",
       "      <td>0.854 ± 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>{'ccp_alpha': 4.959218335617341e-06, 'criterio...</td>\n",
       "      <td>0.898 ± 0.004</td>\n",
       "      <td>0.843 ± 0.004</td>\n",
       "      <td>0.903 ± 0.001</td>\n",
       "      <td>0.845 ± 0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank                                             params balanced_accuracy  \\\n",
       "0     1  {'ccp_alpha': 5.141449890033588e-06, 'criterio...     0.900 ± 0.003   \n",
       "1     2  {'ccp_alpha': 4.803358932542255e-06, 'criterio...     0.900 ± 0.002   \n",
       "2     3  {'ccp_alpha': 5.052652197728508e-06, 'criterio...     0.899 ± 0.002   \n",
       "3     4  {'ccp_alpha': 4.718810292020584e-06, 'criterio...     0.899 ± 0.002   \n",
       "4     5  {'ccp_alpha': 4.959218335617341e-06, 'criterio...     0.898 ± 0.004   \n",
       "\n",
       "        macro_f1    weighted_f1            mcc  \n",
       "0  0.854 ± 0.003  0.913 ± 0.001  0.860 ± 0.002  \n",
       "1  0.844 ± 0.003  0.907 ± 0.001  0.852 ± 0.002  \n",
       "2  0.843 ± 0.002  0.906 ± 0.001  0.850 ± 0.002  \n",
       "3  0.846 ± 0.002  0.909 ± 0.001  0.854 ± 0.002  \n",
       "4  0.843 ± 0.004  0.903 ± 0.001  0.845 ± 0.002  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ababb9-3d68-4354-b94a-eef5a36755e8",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f99675b-ea6e-4250-82c1-4b4367c39ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree model and parameters saved to: tree_artifacts\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Directory for artifacts\n",
    "out_dir = Path(\"tree_artifacts\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "best_tree = bayes.best_estimator_\n",
    "joblib.dump(best_tree, out_dir / \"tree_best_model.pkl\", compress=3)\n",
    "\n",
    "best_params = bayes.best_params_\n",
    "with open(out_dir / \"tree_best_params.json\", \"w\") as f:\n",
    "    json.dump(best_params, f, indent=2)\n",
    "\n",
    "print(\"Tree model and parameters saved to:\", out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dca4cc2-eced-4c12-bc25-0b65c3d15a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df568206-0ebe-4573-99ed-5d2d4a978331",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"tree_artifacts\"\n",
    "import os; os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "best_tree = search.best_estimator_           # already fitted on full training data\n",
    "joblib.dump(best_tree, f\"{out_dir}/tree_best_model.pkl\", compress=3)\n",
    "\n",
    "with open(f\"{out_dir}/tree_best_params.json\", \"w\") as f:\n",
    "    json.dump(search.best_params_, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67dffa4-f6ad-4654-b1e2-29ee95c6157c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c6a1a0-6f38-471e-a96e-328b15d3e26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4637ab-94ad-42e1-b6ec-82d859a1476b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4408047e-3157-4f2d-8683-a03203f61509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa553001-9009-479b-a12e-af72d22b49db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46244182-486b-49cd-8c64-848fe6804fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
